{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Models to ONNX\n",
    "\n",
    "Exporting a pre-trained model to ONNX involves converting the model into a common format that can be easily integrated and deployed across different platforms. The conversion can be done using a tool or library, which converts the model's architecture, weights, and configurations. This allows the model to be used in various applications, such as edge devices, cloud services, and web-based systems, with improved compatibility and performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model\n",
    "\n",
    "The first step is to load any NLP-related model. In this notebook, we will be using a pre-trained GPT-2 model from the Hugging Face's Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to ONNX\n",
    "\n",
    "After the model has been loaded, we call Archai's `export_to_onnx()` method, which wraps all the inner computation of an ONNX export. Additionally, it supports a set of arguments that can be defined according to the input model and task, such as:\n",
    "\n",
    "* `task`: Task identifier to use proper inputs/outputs.\n",
    "* `use_past`: Whether to include past key/values in the model.\n",
    "* `validate`: Whether to validate the exported model.\n",
    "* `share_weights`: Whether to share the embedding and softmax weights.\n",
    "* `opset`: Set of operations to use with ONNX.\n",
    "* `atol`: Tolerance between input and exported model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-03 12:00:00,748 - archai.onnx.export — INFO —  Exporting model: model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gderosa\\Anaconda3\\envs\\archai\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:317: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  past_key, past_value = layer_past\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-03 12:00:14,042 - archai.onnx.export — INFO —  Validating model ...\n",
      "2023-02-03 12:00:14,042 - archai.onnx.onnx_loader — INFO —  Loading model: model.onnx\n",
      "2023-02-03 12:00:15,894 - archai.onnx.export — DEBUG —  Matched outputs: {'present_3', 'present_0', 'present_8', 'present_6', 'present_11', 'present_1', 'present_5', 'present_7', 'present_4', 'present_10', 'present_2', 'present_9', 'probs'}\n",
      "2023-02-03 12:00:15,897 - archai.onnx.export — DEBUG —  Validating output: probs\n",
      "2023-02-03 12:00:15,900 - archai.onnx.export — DEBUG —  Matched shape: (2, 50257) (ONNX) and (2, 50257) (reference)\n",
      "2023-02-03 12:00:15,906 - archai.onnx.export — DEBUG —  Matched difference: 1.0133e-06 < 0.0001\n",
      "2023-02-03 12:00:15,910 - archai.onnx.export — DEBUG —  Validating output: present_0\n",
      "2023-02-03 12:00:15,910 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,916 - archai.onnx.export — DEBUG —  Matched difference: 2.8610e-06 < 0.0001\n",
      "2023-02-03 12:00:15,916 - archai.onnx.export — DEBUG —  Validating output: present_1\n",
      "2023-02-03 12:00:15,921 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,924 - archai.onnx.export — DEBUG —  Matched difference: 4.8876e-06 < 0.0001\n",
      "2023-02-03 12:00:15,924 - archai.onnx.export — DEBUG —  Validating output: present_2\n",
      "2023-02-03 12:00:15,928 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,929 - archai.onnx.export — DEBUG —  Matched difference: 4.2915e-06 < 0.0001\n",
      "2023-02-03 12:00:15,932 - archai.onnx.export — DEBUG —  Validating output: present_3\n",
      "2023-02-03 12:00:15,935 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,938 - archai.onnx.export — DEBUG —  Matched difference: 1.2398e-05 < 0.0001\n",
      "2023-02-03 12:00:15,940 - archai.onnx.export — DEBUG —  Validating output: present_4\n",
      "2023-02-03 12:00:15,943 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,945 - archai.onnx.export — DEBUG —  Matched difference: 1.3351e-05 < 0.0001\n",
      "2023-02-03 12:00:15,946 - archai.onnx.export — DEBUG —  Validating output: present_5\n",
      "2023-02-03 12:00:15,946 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,954 - archai.onnx.export — DEBUG —  Matched difference: 7.6294e-06 < 0.0001\n",
      "2023-02-03 12:00:15,954 - archai.onnx.export — DEBUG —  Validating output: present_6\n",
      "2023-02-03 12:00:15,954 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,954 - archai.onnx.export — DEBUG —  Matched difference: 1.3351e-05 < 0.0001\n",
      "2023-02-03 12:00:15,962 - archai.onnx.export — DEBUG —  Validating output: present_7\n",
      "2023-02-03 12:00:15,962 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,966 - archai.onnx.export — DEBUG —  Matched difference: 7.6294e-06 < 0.0001\n",
      "2023-02-03 12:00:15,970 - archai.onnx.export — DEBUG —  Validating output: present_8\n",
      "2023-02-03 12:00:15,972 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,973 - archai.onnx.export — DEBUG —  Matched difference: 9.0599e-06 < 0.0001\n",
      "2023-02-03 12:00:15,976 - archai.onnx.export — DEBUG —  Validating output: present_9\n",
      "2023-02-03 12:00:15,978 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,982 - archai.onnx.export — DEBUG —  Matched difference: 8.5831e-06 < 0.0001\n",
      "2023-02-03 12:00:15,984 - archai.onnx.export — DEBUG —  Validating output: present_10\n",
      "2023-02-03 12:00:15,987 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,990 - archai.onnx.export — DEBUG —  Matched difference: 7.1526e-06 < 0.0001\n",
      "2023-02-03 12:00:15,990 - archai.onnx.export — DEBUG —  Validating output: present_11\n",
      "2023-02-03 12:00:15,993 - archai.onnx.export — DEBUG —  Matched shape: (2, 2, 12, 16, 64) (ONNX) and (2, 2, 12, 16, 64) (reference)\n",
      "2023-02-03 12:00:15,996 - archai.onnx.export — DEBUG —  Matched difference: 6.9141e-06 < 0.0001\n",
      "Model: 499.16927MB\n"
     ]
    }
   ],
   "source": [
    "from archai.common.file_utils import calculate_onnx_model_size\n",
    "from archai.onnx.export import export_to_onnx\n",
    "\n",
    "onnx_model_path = \"model.onnx\"\n",
    "onnx_config = export_to_onnx(\n",
    "        model,\n",
    "        onnx_model_path,\n",
    "        task=\"causal-lm\",\n",
    "        use_past=True,\n",
    "        share_weights=True,\n",
    "        opset=11,\n",
    "        atol=1e-4,\n",
    "    )\n",
    "print(f\"Model: {calculate_onnx_model_size(onnx_model_path)}MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Export Optimization\n",
    "\n",
    "For Transformer-based models, ONNX Runtime offers a set of post-optimization tools that enables node fusion and hence, a more optimized graph. Thus, we can call `optimize_onnx()` passing the path of the previously exported ONNX model.\n",
    "\n",
    "*The prints compares the models' sizes, but is highly recommended to use an external graph inspection tool, such as Netron.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-03 12:00:18,152 - archai.onnx.optimization — INFO —  Optimizing model: model.onnx\n",
      "failed in shape inference <class 'AssertionError'>\n",
      "Model-OPT: 497.792916MB\n"
     ]
    }
   ],
   "source": [
    "from archai.onnx.optimization import optimize_onnx\n",
    "\n",
    "ort_model_path = optimize_onnx(onnx_model_path, onnx_config, opt_level=1)\n",
    "print(f\"Model-OPT: {calculate_onnx_model_size(ort_model_path)}MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Quantization (PTQ)\n",
    "\n",
    "Finally, either the exported or post-optimized models can be dynamically quantized using the `dynamic_quantization_onnx()` method.\n",
    "\n",
    "Nevertheless, please note that if the model has not been pre-trained with Quantization Aware Training (QAT), it might produce different logits and have its performance diminished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-03 12:00:27,645 - archai.quantization.ptq — INFO —  Quantizing model: model-opt.onnx\n",
      "Model-QNT: 124.886064MB\n"
     ]
    }
   ],
   "source": [
    "from archai.quantization.ptq import dynamic_quantization_onnx\n",
    "\n",
    "qnt_model_path = dynamic_quantization_onnx(ort_model_path)\n",
    "print(f\"Model-QNT: {calculate_onnx_model_size(qnt_model_path)}MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2be478cf8a2d9a6a1293b022e8589530f7ec0d0340a3a36da6068ef3d344086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
