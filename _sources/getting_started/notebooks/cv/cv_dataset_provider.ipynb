{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CV-based Data\n",
    "\n",
    "In this notebook, we will create CV-based data using PyTorch's `torchvision` library, which provides access to popular CV datasets, such as CIFAR10, MNIST, and ImageNet, among others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The first step is to create an instance of the `MnistDatasetProvider`, which offers pre-loads the dataset and offers three methods to retrieve them: `get_train_dataset()`, `get_val_dataset()` and `get_test_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: dataroot\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: dataroot\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "from archai.datasets.cv.mnist_dataset_provider import MnistDatasetProvider\n",
    "\n",
    "dataset_provider = MnistDatasetProvider()\n",
    "\n",
    "train_dataset = dataset_provider.get_train_dataset()\n",
    "val_dataset = dataset_provider.get_val_dataset()\n",
    "print(train_dataset, val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Data\n",
    "\n",
    "Additionally, the `torchvision` library supports various data augmentation techniques, such as random cropping, flipping, and rotation, to increase the size and diversity of the dataset, leading to better model generalization and performance. This can be applied as a post-processing function or by passing the `transform` argument when retrieving the dataset.\n",
    "\n",
    "*By default, every dataset retrieved by the dataset providers use the `ToTensor()` transform.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: dataroot\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transformed_train_dataset = dataset_provider.get_train_dataset(transform=transform)\n",
    "print(transformed_train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2be478cf8a2d9a6a1293b022e8589530f7ec0d0340a3a36da6068ef3d344086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
