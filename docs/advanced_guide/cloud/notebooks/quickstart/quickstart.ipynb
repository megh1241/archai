{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QuickStart\n",
        "\n",
        "In this Notebook we run Archai's [Quickstart](https://microsoft.github.io/archai/getting_started/quick_start.html) example on Azure Machine Learning.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.7 or later\n",
        "- An Azure subscription\n",
        "- An Azure Resource Group\n",
        "- An Azure Machine Learning [Workspace](https://learn.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources#create-the-workspace)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install azure-ai-ml azure-identity \n",
        "%pip install jinja2\n",
        "%pip install archai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "from azure.ai.ml import Output, command\n",
        "\n",
        "import archai.common.azureml_helper as aml_helper\n",
        "import archai.common.notebook_helper as nb_helper"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Get a handle to the workspace\n",
        "\n",
        "We load the workspace from a workspace [configuration file](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#local-and-dsvm-only-create-a-workspace-configuration-file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675428777177
        }
      },
      "outputs": [],
      "source": [
        "ml_client = aml_helper.get_aml_client_from_file(\"../.azureml/config.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a compute cluster\n",
        "\n",
        "We provision a Linux [compute cluster](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python) fos this Notebook. See the [full list](https://azure.microsoft.com/en-ca/pricing/details/machine-learning/) on VM sizes and prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675428792174
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cpu_compute_name = \"nas-cpu-cluster-D14-v2\"\n",
        "aml_helper.create_compute_cluster(ml_client, cpu_compute_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create an environment based on a YAML file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675428814037
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "archai_job_env = aml_helper.create_environment_from_file(ml_client, conda_file=\"conda.yaml\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675429833672
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "job = command(experiment_name=\"archai_quickstart\",\n",
        "              display_name=\"Archai's QuickStart\",\n",
        "              compute=cpu_compute_name,\n",
        "              environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
        "              code=\"main.py\",\n",
        "              outputs=dict(\n",
        "                  output_path=Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
        "              ),\n",
        "              command=\"python main.py --output_dir ${{outputs.output_path}}\"\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Run job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675429838269
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "quickstart_job = ml_client.create_or_update(job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stream logs of the job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client.jobs.stream(quickstart_job.name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download job's output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_name = \"output_path\"\n",
        "download_path = \"output\"\n",
        "\n",
        "aml_helper.download_job_output(ml_client, job_name=quickstart_job.name, output_name=output_name, download_path=download_path)\n",
        "\n",
        "downloaded_folder = Path(download_path) / \"named-outputs\" / output_name"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show Pareto Frontiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_vs_latency_img = Image(filename=downloaded_folder / \"pareto_non_embedding_params_vs_onnx_latency.png\")\n",
        "display(param_vs_latency_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_vs_memory_img = Image(filename=downloaded_folder / \"pareto_non_embedding_params_vs_onnx_memory.png\")\n",
        "display(param_vs_memory_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latency_vs_memory_img = Image(filename=downloaded_folder / \"pareto_onnx_latency_vs_onnx_memory.png\")\n",
        "display(latency_vs_memory_img)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show search state of the last iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = nb_helper.get_search_csv(downloaded_folder)\n",
        "csv_as_html = nb_helper.get_csv_as_stylized_html(df)\n",
        "display(HTML(csv_as_html))"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "archai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d4293aab49b039cc0cdcd865f65e47bb7838862d84c380ef42d6c53ee313261"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
