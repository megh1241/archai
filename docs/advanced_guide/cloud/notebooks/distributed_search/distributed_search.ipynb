{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using storage account: archaimnistmodels\n"
     ]
    }
   ],
   "source": [
    "# Connect to Azure Machine Learning Workspace \n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import archai.common.azureml_helper as aml_helper\n",
    "\n",
    "sys.path.append(os.path.realpath('scripts'))\n",
    "\n",
    "from cnn_search_space import CNNSearchSpace\n",
    "\n",
    "# make sure we have a scripts dir for the code to run our jobs.\n",
    "import os\n",
    "scripts_dir = \"./scripts\"\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "\n",
    "config_file = \"../.azureml/config.json\"\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "for required_key in ['subscription_id', 'resource_group', 'workspace_name', 'storage_account_key', 'storage_account_name']:\n",
    "    if not required_key in config:\n",
    "        print(f\"### Error: please add a {required_key} to {config_file}\")\n",
    "\n",
    "storage_account_key = config['storage_account_key']    \n",
    "storage_account_name = config['storage_account_name']\n",
    "\n",
    "print(f'Using storage account: {storage_account_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ..\\.azureml\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = aml_helper.get_aml_client_from_file(config_path=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named nas-cpu-cluster-D14-v2, we'll reuse it as is.\n",
      "You already have a cluster named nas-gpu-cluster-NC6, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "# Create cpu cluster for running the search\n",
    "cpu_compute_name = \"nas-cpu-cluster-D14-v2\"\n",
    "aml_helper.create_compute_cluster(ml_client, cpu_compute_name, size=\"Standard_D14_v2\", location=\"westus\")\n",
    "\n",
    "# Create gpu cluster for running the search\n",
    "gpu_compute_name = \"nas-gpu-cluster-NC6\"\n",
    "aml_helper.create_compute_cluster(ml_client, gpu_compute_name, size=\"Standard_NC6\", location=\"westus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name aml-archai is registered to workspace, the environment version is 0.1.4\n"
     ]
    }
   ],
   "source": [
    "archai_job_env = aml_helper.create_environment_from_file(ml_client, conda_file=\"conda.yaml\", version='0.1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'models', 'description': 'Datastore pointing to our models blob container.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/datastores/models', 'Resource__source_path': None, 'base_path': 'd:\\\\git\\\\microsoft\\\\archai\\\\docs\\\\advanced_guide\\\\cloud\\\\notebooks\\\\distributed_search', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C93183F460>, 'credentials': {'type': 'account_key'}, 'container_name': 'models', 'account_name': 'archaimnistmodels', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AzureBlobDatastore\n",
    "from azure.ai.ml.entities._credentials import AccountKeyConfiguration\n",
    "\n",
    "model_container_name = \"models\"\n",
    "# Create a blob store container for storing our NAS generated models in.\n",
    "blob_store = AzureBlobDatastore(\n",
    "    name=\"models\",\n",
    "    description=\"Datastore pointing to our models blob container.\",\n",
    "    account_name=storage_account_name,\n",
    "    container_name=model_container_name,\n",
    "    credentials=AccountKeyConfiguration(\n",
    "        account_key=storage_account_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(blob_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'datasets', 'description': 'Datastore pointing to our dataset container.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/datastores/datasets', 'Resource__source_path': None, 'base_path': 'd:\\\\git\\\\microsoft\\\\archai\\\\docs\\\\advanced_guide\\\\cloud\\\\notebooks\\\\distributed_search', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001C93183F4F0>, 'credentials': {'type': 'account_key'}, 'container_name': 'datasets', 'account_name': 'archaimnistmodels', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the datastore with AML\n",
    "data_store_name = \"datasets\"\n",
    "data_container_name = \"datasets\"\n",
    "\n",
    "data_store = AzureBlobDatastore(\n",
    "    name=data_store_name,\n",
    "    description=\"Datastore pointing to our dataset container.\",\n",
    "    account_name=storage_account_name,\n",
    "    container_name=data_container_name,\n",
    "    credentials=AccountKeyConfiguration(\n",
    "        account_key=storage_account_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from store import ArchaiStore\n",
    "\n",
    "# make sure the datasets container exists\n",
    "store = ArchaiStore(storage_account_key, storage_account_name, blob_container_name=data_container_name)\n",
    "store.upload_blob(\"MNIST\", config_file)\n",
    "\n",
    "# make sure the models container exists\n",
    "store = ArchaiStore(storage_account_key, storage_account_name, blob_container_name=model_container_name)\n",
    "store.upload_blob(\"config\", config_file)\n",
    "\n",
    "datastore_path = f'azureml://datastores/{data_store_name}/paths/MNIST/'\n",
    "results_path = f'azureml://datastores/{model_container_name}/paths/MNIST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "\n",
    "data_prep_component = command(\n",
    "    name=\"data_prep2\",\n",
    "    display_name=\"Data preparation for training\",\n",
    "    description=\"Downloads the remote dataset to our blob store.\",\n",
    "    inputs= {\n",
    "        \"name\": Input(type='string')\n",
    "    },\n",
    "    outputs= {\n",
    "        \"data\": Output(type=\"uri_folder\", path=datastore_path, mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 prep_data_store.py \\\n",
    "            --path ${{outputs.data}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = f'{archai_job_env.name}:{archai_job_env.version}'\n",
    "hex_config = bytes(json.dumps(config), encoding='utf-8').hex()\n",
    "\n",
    "search_component = command(\n",
    "    name=\"search\",\n",
    "    display_name=\"The Archai NAS search\",\n",
    "    description=\"Runs the NAS search algorithm.\",    \n",
    "    inputs= {\n",
    "        \"data\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs= {\n",
    "        \"results\": Output(type=\"uri_folder\", path=results_path, mode=\"rw_mount\")\n",
    "    },\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 search.py \\\n",
    "            --data_dir ${{inputs.data}} \\\n",
    "            --output_dir ${{outputs.results}} \"\"\" + \\\n",
    "            f'--environment {environment_name} ' + \\\n",
    "            f'--compute {gpu_compute_name} ' + \\\n",
    "            f'--config {hex_config}',\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_name,\n",
    "    description=\"Data prep pipeline2\",\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = data_prep_component(\n",
    "        name=\"MNIST\"\n",
    "    )\n",
    "\n",
    "    # check the dataset\n",
    "    check_job = search_component(\n",
    "        data=data_prep_job.outputs.data\n",
    "    )\n",
    "    \n",
    "    return { \"data\": data_prep_job.outputs.data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = mnist_pipeline()\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"mnist_test_run\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-archai:0.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"{archai_job_env.name}:{archai_job_env.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_PYTHON_SDK_TYPE_MAPPING\n",
      "_SchemaValidatableMixin__base_path_for_validation\n",
      "_SchemaValidatableMixin__schema_validate\n",
      "__abstractmethods__\n",
      "__class__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__slotnames__\n",
      "__slots__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_abc_impl\n",
      "_build_input\n",
      "_build_inputs\n",
      "_build_inputs_dict\n",
      "_build_inputs_dict_without_meta\n",
      "_build_output\n",
      "_build_output_for_pipeline\n",
      "_build_outputs\n",
      "_build_outputs_dict\n",
      "_build_outputs_dict_without_meta\n",
      "_build_pipeline_outputs_dict\n",
      "_check_private_preview_features\n",
      "_component_items_from_path\n",
      "_create_empty_validation_result\n",
      "_create_schema_for_validation\n",
      "_create_schema_for_validation_with_base_path\n",
      "_customized_validate\n",
      "_dump_for_validation\n",
      "_find_source_from_other_jobs\n",
      "_find_source_from_parent_inputs\n",
      "_find_source_from_parent_outputs\n",
      "_find_source_input_output_type\n",
      "_from_rest_inputs\n",
      "_from_rest_object\n",
      "_from_rest_outputs\n",
      "_get_arm_resource\n",
      "_get_arm_resource_and_params\n",
      "_get_base_info_dict\n",
      "_get_default_input_val\n",
      "_get_skip_fields_in_schema_validation\n",
      "_get_telemetry_values\n",
      "_get_validation_error_target\n",
      "_input_entity_to_rest_inputs\n",
      "_load\n",
      "_load_from_dict\n",
      "_load_from_rest\n",
      "_remove_pipeline_input\n",
      "_repr_html_\n",
      "_resolve_cls_and_type\n",
      "_schema_for_validation\n",
      "_skip_required_compute_missing_validation\n",
      "_source_path\n",
      "_to_component\n",
      "_to_dict\n",
      "_to_input\n",
      "_to_input_builder_function\n",
      "_to_inputs\n",
      "_to_node\n",
      "_to_output\n",
      "_to_outputs\n",
      "_to_rest_inputs\n",
      "_to_rest_object\n",
      "_to_rest_outputs\n",
      "_to_yaml\n",
      "_validate\n",
      "_validate_compute_is_set\n",
      "_validate_group_input_type\n",
      "_validate_init_finalize_job\n",
      "_validate_input\n",
      "base_path\n",
      "creation_context\n",
      "dump\n",
      "id\n",
      "inputs\n",
      "jobs\n",
      "log_files\n",
      "outputs\n",
      "settings\n",
      "status\n",
      "studio_url\n",
      "type\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_name,\n",
    "    description=\"Archai MNIST search\",\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = data_prep_component(\n",
    "        name=\"MNIST\"\n",
    "    )\n",
    "\n",
    "    # check the dataset\n",
    "    check_job = search_component(\n",
    "        data=data_prep_job.outputs.data\n",
    "    )\n",
    "    \n",
    "    return { \"data\": data_prep_job.outputs.data }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "799abcba35f70097d02fca042963180a03ec3451fe1b7671ac5d22383cd0232c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
