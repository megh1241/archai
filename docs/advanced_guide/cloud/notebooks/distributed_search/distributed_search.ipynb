{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Azure Machine Learning Workspace \n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import archai.common.azureml_helper as aml_helper\n",
    "\n",
    "sys.path.append(os.path.realpath('scripts'))\n",
    "\n",
    "from cnn_search_space import CNNSearchSpace\n",
    "\n",
    "# make sure we have a scripts dir for the code to run our jobs.\n",
    "import os\n",
    "scripts_dir = \"./scripts\"\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "\n",
    "config_file = \"../.azureml/config.json\"\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "for required_key in ['subscription_id', 'resource_group', 'workspace_name', 'storage_account_key', 'storage_account_name']:\n",
    "    if not required_key in config:\n",
    "        print(f\"### Error: please add a {required_key} to {config_file}\")\n",
    "\n",
    "storage_account_key = config['storage_account_key']    \n",
    "storage_account_name = config['storage_account_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ..\\.azureml\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = aml_helper.get_aml_client_from_file(config_path=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named nas-cpu-cluster-D14-v2, we'll reuse it as is.\n",
      "You already have a cluster named nas-gpu-cluster-NC6, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "# Create cpu cluster for running the search\n",
    "cpu_compute_name = \"nas-cpu-cluster-D14-v2\"\n",
    "aml_helper.create_compute_cluster(ml_client, cpu_compute_name, size=\"Standard_D14_v2\", location=\"westus\")\n",
    "\n",
    "# Create gpu cluster for running the search\n",
    "gpu_compute_name = \"nas-gpu-cluster-NC6\"\n",
    "aml_helper.create_compute_cluster(ml_client, gpu_compute_name, size=\"Standard_NC6\", location=\"westus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name aml-archai is registered to workspace, the environment version is 0.1.3\n"
     ]
    }
   ],
   "source": [
    "archai_job_env = aml_helper.create_environment_from_file(ml_client, conda_file=\"conda.yaml\", version='0.1.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'models', 'description': 'Datastore pointing to our models blob container.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/datastores/models', 'Resource__source_path': None, 'base_path': 'd:\\\\git\\\\microsoft\\\\archai\\\\docs\\\\advanced_guide\\\\cloud\\\\notebooks\\\\distributed_search', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x00000273F1710E20>, 'credentials': {'type': 'account_key'}, 'container_name': 'models', 'account_name': 'archaimnistmodels', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AzureBlobDatastore\n",
    "from azure.ai.ml.entities._credentials import AccountKeyConfiguration\n",
    "\n",
    "# Create a blob store container for storing our NAS generated models in.\n",
    "blob_store = AzureBlobDatastore(\n",
    "    name=\"models\",\n",
    "    description=\"Datastore pointing to our models blob container.\",\n",
    "    account_name=storage_account_name,\n",
    "    container_name=\"models\",\n",
    "    credentials=AccountKeyConfiguration(\n",
    "        account_key=storage_account_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(blob_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from store import ArchaiStore\n",
    "\n",
    "# make sure the datasets container exists\n",
    "data_container_name = \"datasets\"\n",
    "store = ArchaiStore(storage_account_key, storage_account_name, blob_container_name=data_container_name)\n",
    "store.upload_blob(\"MNIST\", config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'datasets', 'description': 'Datastore pointing to our dataset container.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/datastores/datasets', 'Resource__source_path': None, 'base_path': 'd:\\\\git\\\\microsoft\\\\archai\\\\docs\\\\advanced_guide\\\\cloud\\\\notebooks\\\\distributed_search', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000027389C81C60>, 'credentials': {'type': 'account_key'}, 'container_name': 'datasets', 'account_name': 'archaimnistmodels', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a blob store container for storing our dataset and register it with AML\n",
    "store.get_or_create_dataset_container()\n",
    "\n",
    "data_store_name = \"datasets\"\n",
    "\n",
    "data_store = AzureBlobDatastore(\n",
    "    name=data_store_name,\n",
    "    description=\"Datastore pointing to our dataset container.\",\n",
    "    account_name=storage_account_name,\n",
    "    container_name=data_container_name,\n",
    "    credentials=AccountKeyConfiguration(\n",
    "        account_key=storage_account_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "datastore_path = f'azureml://datastores/{data_store_name}/paths/MNIST/'\n",
    "\n",
    "data_prep_component = command(\n",
    "    name=\"data_prep2\",\n",
    "    display_name=\"Data preparation for training\",\n",
    "    description=\"Downloads the remote dataset to our blob store.\",\n",
    "    inputs= {\n",
    "        \"name\": Input(type='string')\n",
    "    },\n",
    "    outputs= {\n",
    "        \"data\": Output(type=\"uri_folder\", path=datastore_path, mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 prep_data_store.py \\\n",
    "            --path ${{outputs.data}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_component = command(\n",
    "    name=\"check_data2\",\n",
    "    display_name=\"Ensure the data prep step worked\",\n",
    "    description=\"Checks the data exists in the mounted blob store folder.\",    \n",
    "    inputs= {\n",
    "        \"data\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"ls -R ${{inputs.data}}\",\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_name,\n",
    "    description=\"Data prep pipeline2\",\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = data_prep_component(\n",
    "        name=\"MNIST\"\n",
    "    )\n",
    "\n",
    "    # check the dataset\n",
    "    check_job = check_data_component(\n",
    "        data=data_prep_job.outputs.data\n",
    "    )\n",
    "    \n",
    "    return { \"data\": data_prep_job.outputs.data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading scripts (0.03 MBs): 100%|##########| 28545/28545 [00:00<00:00, 346508.78it/s]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = mnist_pipeline()\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"mnist_test_run\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "799abcba35f70097d02fca042963180a03ec3451fe1b7671ac5d22383cd0232c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
