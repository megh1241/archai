{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using storage account: archaimnistmodels\n"
     ]
    }
   ],
   "source": [
    "# Connect to Azure Machine Learning Workspace \n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import archai.common.azureml_helper as aml_helper\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration\n",
    "\n",
    "sys.path.append(os.path.realpath('scripts'))\n",
    "\n",
    "from cnn_search_space import CNNSearchSpace\n",
    "\n",
    "# make sure we have a scripts dir for the code to run our jobs.\n",
    "import os\n",
    "scripts_dir = \"./scripts\"\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "\n",
    "config_file = \"../.azureml/config.json\"\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "for required_key in ['subscription_id', 'resource_group', 'workspace_name', 'storage_account_key', 'storage_account_name']:\n",
    "    if not required_key in config:\n",
    "        print(f\"### Error: please add a {required_key} to {config_file}\")\n",
    "\n",
    "storage_account_key = config['storage_account_key']    \n",
    "storage_account_name = config['storage_account_name']\n",
    "\n",
    "print(f'Using storage account: {storage_account_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ..\\.azureml\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using workspace \"snpe-aml-workspace\" in resource group \"snpe-aml-rg\"\n",
      "Using subscription \"c8b7f913-60fb-4759-a310-fc5630e56f99\"\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = aml_helper.get_aml_client_from_file(config_path=config_file)\n",
    "print(f'Using workspace \"{ml_client.workspace_name}\" in resource group \"{ml_client.resource_group_name}\"')\n",
    "print(f'Using subscription \"{ml_client.subscription_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named nas-cpu-cluster-D14-v2, we'll reuse it as is.\n",
      "You already have a cluster named nas-gpu-cluster-NC6, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "# Create cpu cluster for running the search\n",
    "cpu_compute_name = \"nas-cpu-cluster-D14-v2\"\n",
    "aml_helper.create_compute_cluster(ml_client, cpu_compute_name, size=\"Standard_D14_v2\", location=\"westus2\")\n",
    "\n",
    "# Create gpu cluster for running the search\n",
    "gpu_compute_name = \"nas-gpu-cluster-NC6\"\n",
    "aml_helper.create_compute_cluster(ml_client, gpu_compute_name, size=\"Standard_NC6\", location=\"westus2\", max_instances=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name aml-archai is registered to workspace, the environment version is 0.1.5\n"
     ]
    }
   ],
   "source": [
    "archai_job_env = aml_helper.create_environment_from_file(ml_client, conda_file=\"conda.yaml\", version='0.1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from store import ArchaiStore\n",
    "\n",
    "# Register the datastore with AML\n",
    "data_store_name = \"datasets\"\n",
    "data_container_name = \"datasets\"\n",
    "model_store_name = \"models\"\n",
    "model_container_name = \"models\"\n",
    "\n",
    "# make sure the datasets container exists\n",
    "store = ArchaiStore(storage_account_name, storage_account_key, blob_container_name=data_container_name)\n",
    "store.upload_blob(\"MNIST\", config_file)\n",
    "\n",
    "# make sure the models container exists\n",
    "store = ArchaiStore(storage_account_name, storage_account_key, blob_container_name=model_container_name)\n",
    "store.upload_blob(\"config\", config_file)\n",
    "\n",
    "datastore_path = f'azureml://datastores/{data_store_name}/paths/MNIST'\n",
    "results_path = f'azureml://datastores/{model_store_name}/paths/MNIST'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AzureBlobDatastore\n",
    "from azure.ai.ml.entities._credentials import AccountKeyConfiguration\n",
    "\n",
    "try:\n",
    "    model_store = ml_client.datastores.get(model_store_name)\n",
    "except:\n",
    "    # Register the blob store container for storing our NAS generated models in.\n",
    "    model_store = AzureBlobDatastore(\n",
    "        name=model_store_name,\n",
    "        description=\"Datastore pointing to our models blob container.\",\n",
    "        account_name=storage_account_name,\n",
    "        container_name=model_container_name,\n",
    "        credentials=AccountKeyConfiguration(\n",
    "            account_key=storage_account_key\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ml_client.create_or_update(model_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_store = ml_client.datastores.get(data_store_name)\n",
    "except:\n",
    "    data_store = AzureBlobDatastore(\n",
    "        name=data_store_name,\n",
    "        description=\"Datastore pointing to our dataset container.\",\n",
    "        account_name=storage_account_name,\n",
    "        container_name=data_container_name,\n",
    "        credentials=AccountKeyConfiguration(\n",
    "            account_key=storage_account_key\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ml_client.create_or_update(data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "data_prep_component = command(\n",
    "    name=\"data_prep2\",\n",
    "    display_name=\"Data preparation for training\",\n",
    "    description=\"Downloads the remote dataset to our blob store.\",\n",
    "    inputs= {\n",
    "        \"name\": Input(type='string')\n",
    "    },\n",
    "    outputs= {\n",
    "        \"data\": Output(type=\"uri_folder\", path=datastore_path, mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 prep_data_store.py \\\n",
    "            --path ${{outputs.data}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-archai:0.1.5\n",
      "python3 search.py --data_dir azureml://datastores/datasets/paths/MNIST --output_dir azureml://datastores/models/paths/MNIST --environment \"aml-archai:0.1.5\" --compute \"nas-gpu-cluster-NC6\" --config \"7b22737562736372697074696f6e5f6964223a202263386237663931332d363066622d343735392d613331302d666335363330653536663939222c20227265736f757263655f67726f7570223a2022736e70652d616d6c2d7267222c2022776f726b73706163655f6e616d65223a2022736e70652d616d6c2d776f726b7370616365222c2022696f745f7265736f757263655f67726f7570223a2022736e70652d6465766963652d6875622d7267222c2022696f745f6875625f6e616d65223a20224d7372536e7065446576696365487562222c20226c6f636174696f6e223a202277657374757332222c202273746f726167655f6163636f756e745f6b6579223a202279485a4459454c3045774a65754c54517747395047713867564f6d78777031593836686e54367239735732666659535967686f4c496a694973712f4353454e45766471785a78546b713872482b4153747548445944773d3d222c202273746f726167655f6163636f756e745f6e616d65223a20226172636861696d6e6973746d6f64656c73227d\"\n"
     ]
    }
   ],
   "source": [
    "environment_name = f'{archai_job_env.name}:{archai_job_env.version}'\n",
    "hex_config = bytes(json.dumps(config), encoding='utf-8').hex()\n",
    "\n",
    "search_component = command(\n",
    "    name=\"search\",\n",
    "    display_name=\"The Archai NAS search\",\n",
    "    description=\"Runs the NAS search algorithm.\",    \n",
    "    inputs= {\n",
    "        \"data\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs= {\n",
    "        \"results\": Output(type=\"uri_folder\", path=results_path, mode=\"rw_mount\")\n",
    "    },\n",
    "    code=scripts_dir,\n",
    "    identity= UserIdentityConfiguration(),\n",
    "    command='python3 search.py ' + \\\n",
    "            f'--data_dir {datastore_path} ' + \\\n",
    "            f'--output_dir {results_path} ' + \\\n",
    "            f'--environment \"{environment_name}\" ' + \\\n",
    "            f'--compute \"{gpu_compute_name}\" ' + \\\n",
    "            f'--config \"{hex_config}\"',\n",
    "    environment=f\"{archai_job_env.name}:{archai_job_env.version}\",\n",
    ")\n",
    "print(f\"{archai_job_env.name}:{archai_job_env.version}\")\n",
    "print(search_component.command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_name,\n",
    "    description=\"Data prep pipeline2\",\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = data_prep_component(\n",
    "        name=\"MNIST\"\n",
    "    )\n",
    "\n",
    "    # check the dataset\n",
    "    check_job = search_component(\n",
    "        data=data_prep_job.outputs.data\n",
    "    )\n",
    "    \n",
    "    return { \"data\": data_prep_job.outputs.data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading scripts (0.05 MBs): 100%|##########| 45014/45014 [00:01<00:00, 42621.20it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = mnist_pipeline()\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"mnist_test_run\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "799abcba35f70097d02fca042963180a03ec3451fe1b7671ac5d22383cd0232c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
